{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assembly ANN Solution",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JQVyLscxqj2R"
      },
      "source": [
        "#**Assembly Workshop -- Artificial Neural Networks**\r\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQ7V6g2BxDAT"
      },
      "source": [
        "##**Part One - Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CpLq_a9xTsS"
      },
      "source": [
        "##**Step 1: Import the required libraries**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ryLJLUNmxc_Z"
      },
      "source": [
        "Import the numpy, pandas, and tensorflow libraries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9hOu6axEx4nq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e60cdb6f-84fa-44b0-b228-23cd2791a6f8"
      },
      "source": [
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import tensorflow as tf\r\n",
        "tf.__version__"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.4.0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZa5zZ1kxvgK"
      },
      "source": [
        "##**Step 2: Import the dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yNAfBz4Qx5fy"
      },
      "source": [
        "Our dataset is a .csv file, which we can read using the pandas library. Then, we will remove the unused columns from our x (features), and separate the label column.\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "otFjft9xxcdJ"
      },
      "source": [
        "dataset = pd.read_csv('Churn_Modelling.csv')\r\n",
        "\r\n",
        "x = dataset.iloc[:, 3:-1].values\r\n",
        "y = dataset.iloc[:, -1].values"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vokaoPAjyn39"
      },
      "source": [
        "##**Step 3: Encoding the Data**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JVYg3KjgywB-"
      },
      "source": [
        "Using the following data preprocessing tools, we will first encode the gender column (male = 1, female = 0), and one-hot encode the Geography column (since we only have 3 countries)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ytll4OPsxSzz"
      },
      "source": [
        "from sklearn.preprocessing import LabelEncoder\r\n",
        "le = LabelEncoder()\r\n",
        "x[:, 2] = le.fit_transform(x[:, 2]) "
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EjmnEnMeqjOa"
      },
      "source": [
        "from sklearn.compose import ColumnTransformer\r\n",
        "from sklearn.preprocessing import OneHotEncoder\r\n",
        "ct = ColumnTransformer(transformers = [('encoder', OneHotEncoder(), [1])], remainder = 'passthrough')\r\n",
        "x = np.array(ct.fit_transform(x))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjRfo-bDzIl4"
      },
      "source": [
        "##**Step 4: Splitting the dataset**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wpsM9N9XzQj6"
      },
      "source": [
        "Next, we'll split the dataset into a training set and a test set."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACudBgU9zPWz"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\r\n",
        "x_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CHU5J9TzbDJ"
      },
      "source": [
        "##**Step 5: Feature Scaling**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jZRuwbUEz7Mh"
      },
      "source": [
        "Feature scaling is a MUST in deep learning! "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IACSwotSzb3f"
      },
      "source": [
        "from sklearn.preprocessing import StandardScaler\r\n",
        "sc = StandardScaler()\r\n",
        "x_train = sc.fit_transform(x_train)\r\n",
        "x_test = sc.transform(x_test)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fbVabnVt0l6e"
      },
      "source": [
        "#**Part 2: Building the ANN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv8w-77N0qg3"
      },
      "source": [
        "##**Step 1: Initialise the ANN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GXPUuYYT3JgP"
      },
      "source": [
        "To initialise the ANN, we need to find the Sequential class from the tensorflow keras library."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSdFXPc10uFN"
      },
      "source": [
        "ann = tf.keras.models.Sequential()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QXhg5UT60ubt"
      },
      "source": [
        "##**Step 2: Adding the first input layer and hidden layer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "upctF73l3UXP"
      },
      "source": [
        "Next, we will add the Dense class to the ANN by using the .add(layer) function. We will be adding 32 neurons to the first hidden layer using the relu activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2cjgPcVW3HpN"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units = 32, activation = 'relu'))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CbpKmfnV3fVi"
      },
      "source": [
        "##**Step 3: Adding the second hidden layer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WR0uUZzR3iu0"
      },
      "source": [
        "Similarly, add a second hidden layer with 16 neurons, using the relu activation function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uy-3BnVW3iUA"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units = 16, activation = 'relu'))"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ihK0JIYa3ueM"
      },
      "source": [
        "##**Step 4: Adding the output layer**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WQNHbrM534gh"
      },
      "source": [
        "Finally, let's add our last output layer that will have an activation function of sigmoid."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jUnujAZo35DV"
      },
      "source": [
        "ann.add(tf.keras.layers.Dense(units = 1, activation = 'sigmoid'))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tp7C6_YF4UTB"
      },
      "source": [
        "#**Part 3: Training the ANN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hBfkvR1K4YhN"
      },
      "source": [
        "##**Step 1: Compiling the ANN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmYBwjxG4f-H"
      },
      "source": [
        "We'll compile the network using the adam optimizer and the binary crossentropy loss function."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QL_RI-qK4Y09"
      },
      "source": [
        "ann.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "niWQyRv_43a4"
      },
      "source": [
        "##**Step 2: Training the ANN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zKCoqpnu43K1"
      },
      "source": [
        "Using the .fit function, we will train the ANN using a batch size of 32 through 100 epochs."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_U8VKh15DJF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0865142b-7e9b-4cfb-92a1-f4b92635cfa7"
      },
      "source": [
        "ann.fit(x_train, y_train, batch_size = 32, epochs = 100)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "250/250 [==============================] - 1s 1ms/step - loss: 0.5828 - accuracy: 0.6976\n",
            "Epoch 2/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.4242 - accuracy: 0.8178\n",
            "Epoch 3/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3914 - accuracy: 0.8389\n",
            "Epoch 4/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3768 - accuracy: 0.8452\n",
            "Epoch 5/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3524 - accuracy: 0.8536\n",
            "Epoch 6/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3442 - accuracy: 0.8569\n",
            "Epoch 7/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3397 - accuracy: 0.8620\n",
            "Epoch 8/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3433 - accuracy: 0.8554\n",
            "Epoch 9/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3386 - accuracy: 0.8614\n",
            "Epoch 10/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3445 - accuracy: 0.8559\n",
            "Epoch 11/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3410 - accuracy: 0.8582\n",
            "Epoch 12/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3279 - accuracy: 0.8657\n",
            "Epoch 13/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3288 - accuracy: 0.8661\n",
            "Epoch 14/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3390 - accuracy: 0.8613\n",
            "Epoch 15/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3382 - accuracy: 0.8562\n",
            "Epoch 16/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3238 - accuracy: 0.8667\n",
            "Epoch 17/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3185 - accuracy: 0.8709\n",
            "Epoch 18/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3109 - accuracy: 0.8771\n",
            "Epoch 19/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3399 - accuracy: 0.8579\n",
            "Epoch 20/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8608\n",
            "Epoch 21/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3199 - accuracy: 0.8689\n",
            "Epoch 22/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3333 - accuracy: 0.8627\n",
            "Epoch 23/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3299 - accuracy: 0.8634\n",
            "Epoch 24/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3128 - accuracy: 0.8734\n",
            "Epoch 25/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3186 - accuracy: 0.8697\n",
            "Epoch 26/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3192 - accuracy: 0.8679\n",
            "Epoch 27/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3308 - accuracy: 0.8651\n",
            "Epoch 28/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3186 - accuracy: 0.8678\n",
            "Epoch 29/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3160 - accuracy: 0.8710\n",
            "Epoch 30/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3200 - accuracy: 0.8685\n",
            "Epoch 31/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3033 - accuracy: 0.8792\n",
            "Epoch 32/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3115 - accuracy: 0.8742\n",
            "Epoch 33/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3175 - accuracy: 0.8726\n",
            "Epoch 34/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3064 - accuracy: 0.8782\n",
            "Epoch 35/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3193 - accuracy: 0.8651\n",
            "Epoch 36/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3050 - accuracy: 0.8725\n",
            "Epoch 37/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3065 - accuracy: 0.8751\n",
            "Epoch 38/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3089 - accuracy: 0.8743\n",
            "Epoch 39/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3097 - accuracy: 0.8732\n",
            "Epoch 40/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3066 - accuracy: 0.8727\n",
            "Epoch 41/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2945 - accuracy: 0.8830\n",
            "Epoch 42/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3014 - accuracy: 0.8789\n",
            "Epoch 43/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3063 - accuracy: 0.8759\n",
            "Epoch 44/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3102 - accuracy: 0.8743\n",
            "Epoch 45/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3040 - accuracy: 0.8742\n",
            "Epoch 46/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3074 - accuracy: 0.8702\n",
            "Epoch 47/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3000 - accuracy: 0.8805\n",
            "Epoch 48/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2989 - accuracy: 0.8776\n",
            "Epoch 49/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3058 - accuracy: 0.8754\n",
            "Epoch 50/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3036 - accuracy: 0.8713\n",
            "Epoch 51/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3098 - accuracy: 0.8736\n",
            "Epoch 52/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2995 - accuracy: 0.8790\n",
            "Epoch 53/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3102 - accuracy: 0.8758\n",
            "Epoch 54/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3114 - accuracy: 0.8722\n",
            "Epoch 55/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3032 - accuracy: 0.8762\n",
            "Epoch 56/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2972 - accuracy: 0.8799\n",
            "Epoch 57/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3042 - accuracy: 0.8737\n",
            "Epoch 58/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3073 - accuracy: 0.8778\n",
            "Epoch 59/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2973 - accuracy: 0.8825\n",
            "Epoch 60/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3081 - accuracy: 0.8736\n",
            "Epoch 61/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3085 - accuracy: 0.8785\n",
            "Epoch 62/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2940 - accuracy: 0.8838\n",
            "Epoch 63/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2959 - accuracy: 0.8803\n",
            "Epoch 64/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2900 - accuracy: 0.8810\n",
            "Epoch 65/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2955 - accuracy: 0.8797\n",
            "Epoch 66/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2977 - accuracy: 0.8767\n",
            "Epoch 67/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2958 - accuracy: 0.8758\n",
            "Epoch 68/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2917 - accuracy: 0.8816\n",
            "Epoch 69/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2932 - accuracy: 0.8820\n",
            "Epoch 70/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2989 - accuracy: 0.8786\n",
            "Epoch 71/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2952 - accuracy: 0.8788\n",
            "Epoch 72/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2948 - accuracy: 0.8809\n",
            "Epoch 73/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3031 - accuracy: 0.8784\n",
            "Epoch 74/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2950 - accuracy: 0.8829\n",
            "Epoch 75/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3170 - accuracy: 0.8703\n",
            "Epoch 76/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2937 - accuracy: 0.8807\n",
            "Epoch 77/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2890 - accuracy: 0.8832\n",
            "Epoch 78/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2957 - accuracy: 0.8782\n",
            "Epoch 79/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2958 - accuracy: 0.8760\n",
            "Epoch 80/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2975 - accuracy: 0.8757\n",
            "Epoch 81/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2927 - accuracy: 0.8838\n",
            "Epoch 82/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2910 - accuracy: 0.8876\n",
            "Epoch 83/100\n",
            "250/250 [==============================] - 0s 2ms/step - loss: 0.3021 - accuracy: 0.8776\n",
            "Epoch 84/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2831 - accuracy: 0.8848\n",
            "Epoch 85/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2939 - accuracy: 0.8840\n",
            "Epoch 86/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2959 - accuracy: 0.8763\n",
            "Epoch 87/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2884 - accuracy: 0.8819\n",
            "Epoch 88/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2954 - accuracy: 0.8789\n",
            "Epoch 89/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2913 - accuracy: 0.8789\n",
            "Epoch 90/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2902 - accuracy: 0.8807\n",
            "Epoch 91/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2933 - accuracy: 0.8785\n",
            "Epoch 92/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.3019 - accuracy: 0.8773\n",
            "Epoch 93/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2972 - accuracy: 0.8811\n",
            "Epoch 94/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2959 - accuracy: 0.8827\n",
            "Epoch 95/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2855 - accuracy: 0.8846\n",
            "Epoch 96/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2925 - accuracy: 0.8828\n",
            "Epoch 97/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2870 - accuracy: 0.8855\n",
            "Epoch 98/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2873 - accuracy: 0.8814\n",
            "Epoch 99/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2833 - accuracy: 0.8858\n",
            "Epoch 100/100\n",
            "250/250 [==============================] - 0s 1ms/step - loss: 0.2947 - accuracy: 0.8812\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f5ff7f48550>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TarJ-uCY5DlX"
      },
      "source": [
        "Finally, let's see what our neural network looks like!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZcWucH15INv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7631fd1b-37f4-4d45-a3db-b53ed59e975b"
      },
      "source": [
        "print(ann.summary())"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (32, 32)                  416       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (32, 16)                  528       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (32, 1)                   17        \n",
            "=================================================================\n",
            "Total params: 961\n",
            "Trainable params: 961\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vIilHOXm5MIl"
      },
      "source": [
        "#**Part 4: Testing the ANN**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQE20OxA5P_x"
      },
      "source": [
        "**Assume a customer with the following details:**\r\n",
        "\r\n",
        "Geography: Germany\r\n",
        "\r\n",
        "Credit Score: 750\r\n",
        "\r\n",
        "Gender: Male\r\n",
        "\r\n",
        "Age: 30\r\n",
        "\r\n",
        "Tenure: 4 years \r\n",
        "\r\n",
        "Balance:  150,000\r\n",
        "\r\n",
        "Number of Products: 2 \r\n",
        "\r\n",
        "Credit Card? Yes\r\n",
        "\r\n",
        "Active Member?: No\r\n",
        "\r\n",
        "Estimated Salary: 90,000 \r\n",
        "\r\n",
        "**Is this customer going to leave the bank?**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JSoGNNQpBUz8"
      },
      "source": [
        "**Note the following:**\r\n",
        "\r\n",
        "Male: 1\r\n",
        "\r\n",
        "Female: 0\r\n",
        "\r\n",
        "France: [0,0,1]\r\n",
        "\r\n",
        "Germany: [0,1,0]\r\n",
        "\r\n",
        "Spain: [1,0,0]\r\n",
        "\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7n1HRB6XBASt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6eaa4a3-ba1a-4efe-ece3-811c60294dcf"
      },
      "source": [
        "prediction = ann.predict(sc.transform([[0, 1, 0,\r\n",
        "                                        750,\r\n",
        "                                        1,\r\n",
        "                                        30,\r\n",
        "                                        4,\r\n",
        "                                        150000,\r\n",
        "                                        2,\r\n",
        "                                        1,\r\n",
        "                                        0,\r\n",
        "                                        90000]])) \r\n",
        "\r\n",
        "print(prediction)\r\n",
        "if (prediction > 0.5):\r\n",
        "   print('The customer is likely to leave the bank in the following 6 months')\r\n",
        "else:\r\n",
        "   print('The customer is likely to stay for the next 6 months')"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.093328]]\n",
            "The customer is likely to stay for the next 6 months\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eX5xZ5Lp_7dn"
      },
      "source": [
        "**Assume a customer with the following details:**\r\n",
        "\r\n",
        "Geography: France\r\n",
        "\r\n",
        "Credit Score: 608\r\n",
        "\r\n",
        "Gender: Female\r\n",
        "\r\n",
        "Age: 42\r\n",
        "\r\n",
        "Tenure: 8 years \r\n",
        "\r\n",
        "Balance:  160,000\r\n",
        "\r\n",
        "Number of Products: 3 \r\n",
        "\r\n",
        "Credit Card? Yes\r\n",
        "\r\n",
        "Active Member?: No\r\n",
        "\r\n",
        "Estimated Salary: 110,000 \r\n",
        "\r\n",
        "**Is this customer going to leave the bank?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FKFPKZSB_9Ah",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb3c6ccd-56b8-4a9f-c619-0be9f86b9917"
      },
      "source": [
        "prediction = ann.predict(sc.transform([[0, 0, 1,\r\n",
        "                                        608,\r\n",
        "                                        0,\r\n",
        "                                        42,\r\n",
        "                                        8,\r\n",
        "                                        160000,\r\n",
        "                                        3,\r\n",
        "                                        1,\r\n",
        "                                        0,\r\n",
        "                                        110000]])) \r\n",
        "print(prediction)\r\n",
        "if (prediction > 0.5):\r\n",
        "  print('The customer is likely to leave the bank in the following 6 months')\r\n",
        "else:\r\n",
        "  print('The customer is likely to stay for the next 6 months')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[0.99989784]]\n",
            "The customer is likely to leave the bank in the following 6 months\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}